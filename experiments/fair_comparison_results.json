{
  "config": {
    "d_model": 256,
    "vocab_size": 50257,
    "n_layers": 4,
    "n_heads": 8,
    "seq_len": 128,
    "batch_size": 32,
    "learning_rate": 0.0003,
    "max_steps": 2000,
    "eval_interval": 200,
    "mixed_precision": true,
    "gpu": "A10G",
    "dataset": "wikitext-2"
  },
  "baseline_model": "Transformer_MHA",
  "results": {
    "Transformer_MHA": {
      "success": true,
      "model_name": "Transformer_MHA",
      "final_train_loss": 5.101504325866699,
      "eval_loss": 5.6790587425231935,
      "perplexity": 292.6738188121674,
      "steps": 2000,
      "time_seconds": 97.33150053024292,
      "parameters": 30221393,
      "error": null,
      "gpu": "A10G",
      "mixed_precision": true,
      "dataset": "wikitext-2",
      "is_baseline": true
    },
    "Transformer_GQA": {
      "success": true,
      "model_name": "Transformer_GQA",
      "final_train_loss": 5.325674057006836,
      "eval_loss": 5.6781840133667,
      "perplexity": 292.41792042671614,
      "steps": 2000,
      "time_seconds": 97.41512775421143,
      "parameters": 29826641,
      "error": null,
      "gpu": "A10G",
      "mixed_precision": true,
      "dataset": "wikitext-2",
      "is_baseline": false
    },
    "Transformer_MQA": {
      "success": true,
      "model_name": "Transformer_MQA",
      "final_train_loss": 5.286867141723633,
      "eval_loss": 5.664127521514892,
      "perplexity": 288.33630411937804,
      "steps": 2000,
      "time_seconds": 98.0770673751831,
      "parameters": 29760849,
      "error": null,
      "gpu": "A10G",
      "mixed_precision": true,
      "dataset": "wikitext-2",
      "is_baseline": false
    }
  }
}